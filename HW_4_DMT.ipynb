{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LM1997610/Data-Mining/blob/main/HW_4_DMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtqmMBBFM5VB",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "\n",
        "# DMT 2023 - Homework 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1WumsFAdkY-"
      },
      "source": [
        "## Group composition:\n",
        "\n",
        "<br>\n",
        "\n",
        "------------YOUR TEXT STARTS HERE------------\n",
        "\n",
        "<br>\n",
        "\n",
        "- Mazzucco, Luca, 1997610\\\n",
        "- Zilviano, Paolo, 1916518\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa4VRPyugoQC"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqgVm5VodkY_"
      },
      "source": [
        "## Homework 4\n",
        "The homework consists of two parts:\n",
        "\n",
        "  1. Text Representation\n",
        "\n",
        "  and\n",
        "\n",
        "  2. Deep Learning\n",
        "\n",
        "> Ensure that the notebook can be faithfully reproduced by anyone (hint: pseudo random number generation).\n",
        "\n",
        "> If you need to set a random seed, set it to `709`.\n",
        "\n",
        "> If multiple code cells are provided for a single part, it is **NOT** mandatory to use them all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUmFzlrilzdB",
        "tags": []
      },
      "source": [
        "# Part 1\n",
        "In this part of the homework, you have to deal with Text Representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBCzTi5cbLtN"
      },
      "source": [
        "Import **ALL** the Python packages that you need for Part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X9Y4uPGdkY_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "#REMOVE_OUTPUT#\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "!pip install -U sentence-transformers\n",
        "!pip install gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import time; import json; import string\n",
        "import numpy as np; import pandas as pd\n",
        "from tqdm.auto import tqdm; from tabulate import tabulate\n",
        "\n",
        "!pip install py3langid\n",
        "from py3langid.langid import LanguageIdentifier, MODEL_FILE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 20#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6kYyWWxmEQq"
      },
      "source": [
        "## Part 1.1\n",
        "The company **F**antastic **S**olution sells products. Customers can leave product reviews on their platform. The company wants to classify the reviews into positive and negative.\n",
        "\n",
        "Their requirements are unclear: they mention both accuracy and calculation time, but it is not known which is more important to them. :'(\n",
        "\n",
        "They also forbid you to do a hyper-parameter optimisation.\n",
        "(why? :O )\n",
        "\n",
        "To help you (?), they have already pre-processed the data. They have translated each text into a random language.\n",
        "\n",
        "The best thing to do is to provide them with a list of models that can best meet their (unclear) requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iEH-lmorp00"
      },
      "source": [
        "### 1.1.1\n",
        "Download the data from the Drive link (code already provided)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCOOAftWRE5X",
        "outputId": "7994946a-a612-4227-9fff-53b4db5edc37",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1X6QnCcOgnNEBQ1xnilmPWqDIs7bRrQof\n",
            "To: /home/ec2-user/SageMaker/Data-Mining/FS_reviews.jsonl\n",
            "100%|██████████████████████████████████████| 18.3M/18.3M [00:00<00:00, 63.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "#REMOVE_OUTPUT#\n",
        "!gdown 1X6QnCcOgnNEBQ1xnilmPWqDIs7bRrQof"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r36aVr85h3eM"
      },
      "source": [
        "### 1.1.2\n",
        "Understand (!) and pre-process *(general term!)* the data.\n",
        "Divide the data according to your needs.\n",
        "\n",
        "> No specific request\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "19e316032b3947cb8c7547e2582c83ba"
          ]
        },
        "id": "54tCyCDm4YQY",
        "outputId": "af883f39-a5a9-4721-8c2a-fb21f15b010e",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e316032b3947cb8c7547e2582c83ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20210 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.shape: (20210, 10)\n",
            "\n",
            "data.columns: ['unique_id', 'product_name', 'product_type', 'helpful', 'rating', 'title', 'date', 'review_text', 'reviewer', 'reviewer_location']\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "# building the dataframe:\n",
        "with open('FS_reviews.jsonl', 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "lista = [json.loads(review) for review in tqdm(json_list)]\n",
        "\n",
        "df = pd.DataFrame.from_dict(lista)\n",
        "\n",
        "tqdm.pandas()\n",
        "print(\"data.shape:\", df.shape)\n",
        "print(\"\\ndata.columns:\", list(df.columns))\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GyMVhNAuKhc",
        "outputId": "6e315ab7-5a78-47db-95ed-4b0e67023f53",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " data.shape: (18550, 10)\n",
            "\n",
            " rating    count\n",
            "--------  -------\n",
            "   5       11110\n",
            "   4       3784\n",
            "   1       2332\n",
            "   2       1324\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "# data cleaning:\n",
        "\n",
        "df.drop_duplicates(keep=\"first\", inplace=True)\n",
        "\n",
        "df.replace('', None, inplace=True);\n",
        "df = df[df['review_text'] != \"ERROR\"]\n",
        "df = df[df['title'] != \"ERROR\"]\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#df['date'] = pd.to_datetime(df['date'], format='%B %d, %Y')\n",
        "df[\"rating\"] = df[\"rating\"].astype(float).astype(int)\n",
        "\n",
        "print(\"\\n data.shape:\", df.shape)\n",
        "\n",
        "df[\"real_id\"] = df[\"unique_id\"].str.split(\":\").str[0]\n",
        "df[\"product_name\"]  = df[\"product_name\"].str.split(\":\").str[0]\n",
        "\n",
        "df = df.drop('unique_id', axis=1)\n",
        "\n",
        "columns = ['real_id', 'date', 'title', 'review_text',\n",
        "           'rating', 'helpful', 'reviewer', 'reviewer_location',\n",
        "           'product_name', 'product_type']\n",
        "\n",
        "df = df[columns]\n",
        "\n",
        "print()\n",
        "print(tabulate(df[\"rating\"].value_counts().to_frame(), headers=[\"rating\", \"count\"],\n",
        "                                                  numalign='center', stralign=\"center\"))\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c7f26a25d55b405dade9f72c1f496943",
            "48a174c18edf457f8dc0da60aa187fc8"
          ]
        },
        "id": "DzfeaQh_uL8G",
        "outputId": "f6197de6-8574-41f9-974b-25e554b99e2a",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7f26a25d55b405dade9f72c1f496943",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/18550 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a174c18edf457f8dc0da60aa187fc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/18550 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " lingua    count\n",
            "--------  -------\n",
            "   en      9629\n",
            "   it      1838\n",
            "   pl      1623\n",
            "   ko      1563\n",
            "   es      1532\n",
            "   de      1397\n",
            "   tl       539\n",
            "   sw       389\n",
            "   ms       40\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "#################################################\n",
        "def tokenization(text):\n",
        "\n",
        "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "\n",
        "    new_text = text.translate(table).replace(\"\\n\", \" \")\n",
        "    new_text = \" \".join(new_text.lower().split())\n",
        "\n",
        "    return new_text\n",
        "#####################################################\n",
        "\n",
        "#pre-processing text:\n",
        "\n",
        "df[\"processed_text\"] = df[\"review_text\"].progress_apply(lambda desc: tokenization(desc))\n",
        "\n",
        "df[\"class\"] = [0 if i < 3 else 1 for i in df['rating']] # binary classification\n",
        "\n",
        "# language detection:\n",
        "identifier = LanguageIdentifier.from_pickled_model(MODEL_FILE, norm_probs=True)\n",
        "identifier.set_languages(['en', 'it', 'pl', \"ko\", \"es\", \"tl\", \"sw\", \"ms\", \"de\"])\n",
        "\n",
        "df[\"lingua\"] = df[\"processed_text\"].progress_apply(lambda desc: identifier.classify(desc)[0])\n",
        "\n",
        "print()\n",
        "print(tabulate(df[\"lingua\"].value_counts().to_frame(), headers=[\"lingua\", \"count\"],\n",
        "                                                   numalign='center', stralign=\"center\"))\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_AiZBi0OyLZ"
      },
      "source": [
        "Provide an explanation for your preprocessing *(general term!)*.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "Duplicate entries have been eliminated, and mis-registered values have been discarted.\\\n",
        "Regarding the text  we executed removal of punctuation, extra-whitespace, and line breaks.\\\n",
        "Finally, some counts to understand the dataset imbalance regarding ratings and languages.\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRa7Gf0W1eOG"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv0it5bwkDRJ"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gts4IfNwuZFk"
      },
      "source": [
        "### 1.1.3\n",
        "Choose at least 1 and a maximum of 3 encodings. Encode the data.\n",
        "\n",
        "> P.S. If you need it, Word2Vec has a version for Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1f8c7b23c4294347901b6affeccdb3ba",
            "52dacec48c6a4bdaa051a67e4266857b",
            "919c93a973c54bd3888de039f7a33ee4",
            "391224847a04491d953d97dffd194f28",
            "5af83cdb5a3e4886953d857bffb5fe16",
            "008e9f1470004dd5bd627f0c4769d1f1",
            "c6b9273face34883b54475d9b0881716",
            "f62ecf96ed4b40418652c7b4251e40a2",
            "f7d2feedff0c482999384d54ef21de54",
            "55a89aefea9b4a8fa49be4402e5c9711",
            "5b70b56e487a43ef8a7eea5c65daa10c",
            "d66a8c3533614d00babf5138f4f3cd46"
          ]
        },
        "id": "LE75JmBauZFq",
        "outputId": "81337d12-a8aa-4aab-b003-101c3b1b98be",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d66a8c3533614d00babf5138f4f3cd46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/580 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "# 1 Model -> Sentence Embedding using Sentence Transformers:\n",
        "first_model = 'distiluse-base-multilingual-cased-v1'\n",
        "\n",
        "model_one = SentenceTransformer(first_model)\n",
        "\n",
        "embed_one = model_one.encode(df[\"processed_text\"], show_progress_bar=True)\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cfd9513f680e4b749b13188316e6d4f5",
            "8ca274683d004d56870d423d3932cb88",
            "814a414dc4414fc99a6a2f40d5730e25",
            "a0d5159e7fcb4767aff1dcbb57582eb6",
            "6e074e469b3c4de0ade713f93bd88979",
            "0f86700fe7494a41bccc5ac730ddd11f",
            "454f4e6c66944ee08cbda6c7316b6c02",
            "0f25620a669f46b090c85b17a4507d67",
            "90f9ae0d934049d3a6170e2209dc7dda",
            "3b4011bdc37d44a58d5ab1207cb981a8",
            "81b4ecb83ac642b4bf445eb44d191e05",
            "d18a5836a5ca450c857085770b3c0e15"
          ]
        },
        "id": "u8tR1CpvuZFs",
        "outputId": "9aef66de-2c8b-49bb-c329-45c2cfdd73e4",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d18a5836a5ca450c857085770b3c0e15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/580 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "# 2 Model -> Sentence Embedding using Sentence Transformers:\n",
        "second_model = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
        "\n",
        "model_two = SentenceTransformer(second_model)\n",
        "\n",
        "embed_two = model_two.encode(df[\"processed_text\"], show_progress_bar=True)\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNgkVna-uZFs",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_text'], df[\"class\"],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=709)\n",
        "# 3 Model -> Word embedding using Word2Vec:\n",
        "\n",
        "sentences = [sentence.split() for sentence in X_train]\n",
        "w2v_model = Word2Vec(sentences, window=5, min_count=5, workers=4)\n",
        "\n",
        "def vectorize(sentence):\n",
        "    words = sentence.split()\n",
        "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
        "    if len(words_vecs) == 0:\n",
        "        return np.zeros(100)\n",
        "    words_vecs = np.array(words_vecs)\n",
        "    return words_vecs.mean(axis=0)\n",
        "\n",
        "X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
        "X_test = np.array([vectorize(sentence) for sentence in X_test])\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mlovxB9uZFt"
      },
      "source": [
        "Give a reason for your choices.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wYZzvhOvpyP"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "Selected two pretrained-multilingual models from SentenceTransformer, trained on data for 50+ languages, this adequately meets our needs.\n",
        "Then a model based on word embeddings provided by Word2Vec was chosen due to the inability to implement a successful classifier using suggested Doc2Vec..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8xHlrpBuZFt"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az3E65rBvMU5"
      },
      "source": [
        "### 1.1.4\n",
        "Choose **ONE** classifier for **EACH** encoding. Train the classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xK0XFqAvMU9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression;\n",
        "from sklearn.neighbors import KNeighborsClassifier;\n",
        "from sklearn.svm import SVC;\n",
        "\n",
        "classifiers = [SVC(random_state=709), KNeighborsClassifier(), LogisticRegression(max_iter=1000)]\n",
        "\n",
        "######################################\n",
        "\n",
        "def train_the_classifiers(model, tr_x, tr_y):\n",
        "\n",
        "    start = time.time()\n",
        "    model.fit(tr_x, tr_y)\n",
        "    duration = time.time() - start\n",
        "\n",
        "    return round(duration, 4)\n",
        "#######################################################\n",
        "\n",
        "embeddings = embed_one\n",
        "\n",
        "train_x_a, test_x_a, train_y_a, test_y_a = train_test_split(embeddings, df[\"class\"],\n",
        "                                                    test_size=0.2,\n",
        "                                                    shuffle=True, random_state = 709)\n",
        "\n",
        "\n",
        "d_0 = {\"Classifiers\": str(classifiers[0]).split(\"(\")[0],\n",
        "       \"FIT_Time\": train_the_classifiers(classifiers[0], train_x_a, train_y_a)}\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MGAkG0SvMU-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "embeddings = embed_two\n",
        "\n",
        "train_x_b, test_x_b, train_y_b, test_y_b= train_test_split(embeddings, df[\"class\"],\n",
        "                                                    test_size=0.2,\n",
        "                                                    shuffle=True, random_state = 709)\n",
        "\n",
        "\n",
        "d_1 = {\"Classifiers\": str(classifiers[1]).split(\"(\")[0],\n",
        "       \"FIT_Time\": train_the_classifiers(classifiers[1], train_x_b, train_y_b)}\n",
        "\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWDgixeUvMU-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "\n",
        "output = train_the_classifiers(classifiers[2], X_train, y_train)\n",
        "\n",
        "d_2 = {\"Classifiers\": str(classifiers[2]).split(\"(\")[0],\n",
        "       \"FIT_Time\": output}\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW8qInkFvMU-"
      },
      "source": [
        "Provide a justification for your choices.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adcPIIWFvrRT"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "Distinct classifiers have been chosen for each encoding, selecting the most traditional algorithms available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40htroIIvMU_"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qddz7EnRvM0u"
      },
      "source": [
        "### 1.1.5\n",
        "Obtain the metrics you want to show the company."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LefXTMsnv44b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "#########################################################\n",
        "\n",
        "def get_the_metrics(model, tst_x, tst_y, old_diz):\n",
        "\n",
        "    t1 =   time.time()\n",
        "    predicted = model.predict(tst_x)\n",
        "    old_diz[\"Pred_time\"] = round(time.time() - t1, 4)\n",
        "\n",
        "    old_diz[\"Accuracy\"] = round(accuracy_score(tst_y, predicted), 4)\n",
        "\n",
        "    return old_diz\n",
        "\n",
        "#########################################################\n",
        "\n",
        "\n",
        "d_0 = get_the_metrics(classifiers[0], test_x_a, test_y_a, d_0)\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2MS-Xy1v44c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "d_1 = get_the_metrics(classifiers[1], test_x_b, test_y_b, d_1)\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ub6lbzCv44c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "d_2 = get_the_metrics(classifiers[2], X_test, y_test, d_2)\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvdO4jUev44c"
      },
      "source": [
        "Provide a rationale for the choice of metrics.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUlPRJWHv44c"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "Two metrics have been chosen to express \"calculation time\" - specifically, the training time and prediction time.\\\n",
        "Additionally we took into account the accuracy demanded by the company\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDjwaz1mv44c"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdsESNeov5AB"
      },
      "source": [
        "### 1.1.6\n",
        "Provide the company with all the information it needs to choose the pipeline it prefers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xiYyYGyv5AC",
        "tags": [],
        "outputId": "c5d95585-ad15-4a25-eb12-fc4cbd31a44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                           Classifiers        FIT_Time    Pred_time    Accuracy\n",
            "---------------------  --------------------  ----------  -----------  ----------\n",
            "multilingual-cased-v1          SVC            41.0111      10.1812      0.8876\n",
            "    MiniLM-L12-v2      KNeighborsClassifier    0.0033      0.6728       0.8604\n",
            "      Word2vec          LogisticRegression     0.6737      0.0016       0.8113\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "metrics_df = pd.DataFrame.from_dict([d_0, d_1, d_2])\n",
        "\n",
        "name_1 = \"-\".join(first_model.split(\"-\")[2:])\n",
        "name_2 = \"-\".join(second_model.split(\"-\")[2:])\n",
        "\n",
        "metrics_df.index = [name_1, name_2, \"Word2vec\"]\n",
        "\n",
        "print()\n",
        "print(tabulate(metrics_df, headers=metrics_df.columns, numalign='center', stralign=\"center\"))\n",
        "print()\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sy6zgrfv5AD"
      },
      "source": [
        "Describe what you have supplied and why.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwPpJB-Pv5AE"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "Here is a table displaying characteristics and the desired performance for our three models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "___vFWwXwIEi"
      },
      "source": [
        "Also, explain how the company could decide between the classifiers you have produced.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXRyvuEzwIEs"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "In cases where comparable accuracy scores are achieved, it is advisable to opt for the simpler and faster model.\\\n",
        "Then define a balance between fit_time and prediction_time which will depend on the specific needs of the company\\\n",
        "SVC is known to be computationally heavier, but in this case it exhibits the best performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6gux5YNv5AF"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2Cqjb_pdkZJ"
      },
      "source": [
        "# Part 2\n",
        "In this part of the homework, you have to deal with Deep Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1z74VMwdkZJ"
      },
      "source": [
        "Import here **ALL** the Python packages that you need for Part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GchtpxKSdkZJ",
        "tags": [],
        "outputId": "c1808f74-36b2-437a-faca-3a966723f18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "\n",
        "#REMOVE_OUTPUT#\n",
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "!pip install torchtext\n",
        "\n",
        "import torch\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 20#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41U1DuGodkZJ"
      },
      "source": [
        "## Part 2.1\n",
        "You have to use the same data as in Part 1, but you can use whatever adjustments you have made to it (only Part 1.1.2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7O6Cxkg6eN5"
      },
      "source": [
        "### 2.1.1\n",
        "Prepare the data structures you will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3k0Qh846eOI",
        "tags": [],
        "outputId": "497335cd-0d6d-44e7-a643-f5d1021736cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "esempio: [564, 7, 104, 5030]\n",
            "\n",
            "Classes {1, 2, 3, 4, 5} Number classes: 5 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "tuple_list = list(zip(df[\"rating\"], df[\"processed_text\"]))\n",
        "\n",
        "train_size = int(0.8 * len(df))\n",
        "test_size = len(df) - train_size\n",
        "\n",
        "torch.manual_seed(709)\n",
        "\n",
        "train_d, test_d = random_split(tuple_list, [train_size, test_size])\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(iter(train_d)), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "print(\"\\nesempio:\", vocab(['here', 'is', 'an', 'example']))\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1\n",
        "\n",
        "\n",
        "all_classes = set([label for (label, text) in train_d])\n",
        "all_classes.add(3)\n",
        "print(\"\\nClasses\", all_classes, end = \" \")\n",
        "\n",
        "num_class = len(all_classes)\n",
        "print(\"Number classes:\", num_class, \"\\n\")\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW97Q-rY6eOJ",
        "tags": [],
        "outputId": "ff3ddb36-bf8c-48fb-93f6-df66fb5f6b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Device: cuda Tesla T4 on GPU = True\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"\\n Device:\", device, torch.cuda.get_device_name(0), \"on GPU =\", torch.cuda.is_available())\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4qWj2qD6eOJ"
      },
      "source": [
        "Briefly explain relevant parts of your code.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzm-uUsX6eOK"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "Organizing the data in list of tuples, splitting them into training and testing datasets, setting up tokenization and preprocessing functions, initialize a vocabulary, and obtaining the number of classes in the data.\\\n",
        "Then the \"collate_batch\" function to processes a collected batch of data by applying pipelines for label processing and text processing, it converts the text into a tensor, and it returns the label tensor, processed text tensor, and offsets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04CPmR1I6eOK"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0urIbkkiDHOw"
      },
      "source": [
        "### 2.1.2\n",
        "Define your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3u8M0S5DHO5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "\n",
        "class TextClassificationModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "\n",
        "        #Computes sums or means of ‘bags’ of embeddings, without instantiating the intermediate embeddings.\n",
        "        self.embedding = torch.nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "\n",
        "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
        "        #self.layer1 = torch.nn.Linear(embed_dim, num_class)\n",
        "\n",
        "        #we can use multiple linear layers in sequence --> Deep Learning!\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "\n",
        "        return self.fc(embedded)\n",
        "\n",
        "\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "emb_size = 84\n",
        "model = TextClassificationModel(vocab_size, emb_size, num_class).to(device)\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Uxu160ro5O5W"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VrKO9yZDHO7"
      },
      "source": [
        "Briefly explain relevant parts of your code.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiOBD6UZDHO7"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "The code defines a TextClassificationModel class from torch.nn.Module.\\\n",
        "It initializes the model with an embedding layer (EmbeddingBag) and a linear layer (Linear).\\\n",
        "The forward method performs the forward pass of the model, taking input text and offsets, embedding the text, and passing it through the linear layer.\\\n",
        "The model is then instantiated with the defined vocabulary size, embedding size, and number of classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s76tg3SuDHO7"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYg_8baBDHX8"
      },
      "source": [
        "### 2.1.3\n",
        "Train and optimize your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDPk2xRyDHX9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "\n",
        "        #print(  idx, log_interval, idx % log_interval )\n",
        "        if idx % log_interval == 0 and idx>0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader), total_acc/total_count))\n",
        "\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "\n",
        "    return total_acc/total_count\n",
        "\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4KqDvT-DHX-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 7   # learning rate\n",
        "BATCH_SIZE = 6   # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=LR)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "\n",
        "train_iter, test_iter = random_split(tuple_list, [train_size, test_size])\n",
        "\n",
        "train_dataset = to_map_style_dataset((train_iter)) #Convert iterable-style dataset to map-style dataset.\n",
        "test_dataset = to_map_style_dataset((train_iter)) #Convert iterable-style dataset to map-style dataset.\n",
        "\n",
        "num_train = int(len(train_dataset) * 0.75)\n",
        "\n",
        "\n",
        "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCG5mzpLDHX-",
        "tags": [],
        "outputId": "5fc9fa84-5a1d-4b34-91c6-cce19323e72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 1855 batches | accuracy    0.589\n",
            "| epoch   1 |  1000/ 1855 batches | accuracy    0.605\n",
            "| epoch   1 |  1500/ 1855 batches | accuracy    0.615\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  9.95s | valid accuracy    0.600 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1855 batches | accuracy    0.640\n",
            "| epoch   2 |  1000/ 1855 batches | accuracy    0.648\n",
            "| epoch   2 |  1500/ 1855 batches | accuracy    0.671\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  9.97s | valid accuracy    0.621 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1855 batches | accuracy    0.695\n",
            "| epoch   3 |  1000/ 1855 batches | accuracy    0.716\n",
            "| epoch   3 |  1500/ 1855 batches | accuracy    0.735\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  9.91s | valid accuracy    0.634 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1855 batches | accuracy    0.740\n",
            "| epoch   4 |  1000/ 1855 batches | accuracy    0.770\n",
            "| epoch   4 |  1500/ 1855 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  9.88s | valid accuracy    0.647 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1855 batches | accuracy    0.781\n",
            "| epoch   5 |  1000/ 1855 batches | accuracy    0.814\n",
            "| epoch   5 |  1500/ 1855 batches | accuracy    0.813\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  9.98s | valid accuracy    0.650 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1855 batches | accuracy    0.819\n",
            "| epoch   6 |  1000/ 1855 batches | accuracy    0.855\n",
            "| epoch   6 |  1500/ 1855 batches | accuracy    0.843\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  9.91s | valid accuracy    0.654 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1855 batches | accuracy    0.845\n",
            "| epoch   7 |  1000/ 1855 batches | accuracy    0.877\n",
            "| epoch   7 |  1500/ 1855 batches | accuracy    0.872\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  9.90s | valid accuracy    0.649 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1855 batches | accuracy    0.875\n",
            "| epoch   8 |  1000/ 1855 batches | accuracy    0.904\n",
            "| epoch   8 |  1500/ 1855 batches | accuracy    0.915\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  9.88s | valid accuracy    0.659 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1855 batches | accuracy    0.882\n",
            "| epoch   9 |  1000/ 1855 batches | accuracy    0.912\n",
            "| epoch   9 |  1500/ 1855 batches | accuracy    0.919\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  9.93s | valid accuracy    0.660 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1855 batches | accuracy    0.887\n",
            "| epoch  10 |  1000/ 1855 batches | accuracy    0.919\n",
            "| epoch  10 |  1500/ 1855 batches | accuracy    0.923\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  9.93s | valid accuracy    0.659 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ar0943gDHX-"
      },
      "source": [
        "Briefly explain relevant parts of your code.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_r6cHLWDHYA"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "\n",
        "The train function trains the model by iterating over batches, calculating loss, performing backpropagation, and updating the model's parameters.\\\n",
        "The evaluate function evaluates the model's performance on a given set.\\\n",
        "Then defines hyperparameters, creates optimizer and scheduler objects, and iterates over epochs, training the model and evaluating on the validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Go3RYzfDHYA"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSL3LLiRDHgw"
      },
      "source": [
        "### 2.1.4\n",
        "Show the performance of your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBrulVhQDHgx",
        "tags": [],
        "outputId": "adb1a2f5-390c-4632-d935-3a5c2180dc23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checking the results of test dataset...\n",
            " ... test accuracy:    0.847\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "\n",
        "print('\\nChecking the results of test dataset...')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(' ... test accuracy: {:8.3f}'.format(accu_test))\n",
        "\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFuhuM__DHgx",
        "outputId": "95bbd294-d604-4c0f-afae-f20279bf30e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a really_bad review\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "news_label = {1: \"really_bad\", 2: \"bad\", 3: \"mid\", 4 : \"good\", 5 : \"really_good\"}\n",
        "\n",
        "ex_text_str = \"The SuperGadget X5 Multi-Tool is a total disappointment.\\\n",
        "                    Poor build quality, ineffective tools, \\\n",
        "                    and an unappealing design make it a regrettable purchase.\\\n",
        "                    Save your money and explore better options.\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s review\" %news_label[predict(ex_text_str, text_pipeline)])\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDitTkSBDHgx",
        "outputId": "4342342b-558b-4a11-b12b-9a2c695464db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a really_good review \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "\n",
        "\n",
        "text_test = \"The XYZ Portable Bluetooth Speaker exceeded my expectations in every way.\\\n",
        "            The sound quality is exceptional, delivering crystal-clear audio with rich bass.\\\n",
        "            The battery life is impressive, providing hours of uninterrupted music playback.\\\n",
        "            Additionally, the build quality is top-notch, showcasing a sleek and sturdy design.\\\n",
        "            I highly recommend this speaker to anyone looking for a premium audio experience on the go.\"\n",
        "\n",
        "print(\"This is a %s review\" %news_label[predict(text_test, text_pipeline)], \"\\n\")\n",
        "\n",
        "\n",
        "#YOUR CODE ENDS HERE#\n",
        "#THIS IS LINE 40#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duc3RiVKDHgy"
      },
      "source": [
        "Briefly explain relevant parts of your code.\n",
        "\n",
        "**Use at most 3 sentences.**\n",
        "\n",
        "[comment]: <> (#SHOW_CELL#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONY4WLO4DHgy"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "The predict function uses the pre-trained model to predict the sentiment label (ranging from 1 to 5) of a given text.\\\n",
        "Then we apply this function to two example reviewes and prints the corresponding sentiment label for testing purposes\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_UGZgs5DHgy"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lX3qFqGdkZM"
      },
      "source": [
        "## Part 2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx2JVwCqVW3p"
      },
      "source": [
        "### 2.2.1\n",
        "How would a Deep Learning model (of the kind we have seen) behave in the case where a word was never seen during training?\n",
        "Answer on both practical and theoretical aspects.\n",
        "\n",
        "**Use at most 3 sentences.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az4tdEMOVW3t"
      },
      "source": [
        "----------YOUR TEXT STARTS HERE----------\n",
        "\n",
        "<br>\n",
        "\n",
        "Deep learning model use word embeddings, such as Word2Vec or SentenceEmbedding, so when it encounters a word that was never seen during training, the model attempt to find the nearest neighbors in the embedding space for the unseen word.\n",
        "Neural LanguageModels can use similarity among words\n",
        "embeddings to generalize and predict unseen words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhI4Zhpk-1pc"
      },
      "source": [
        "<div style=\"page-break-after: always; visibility: hidden\">\n",
        "\\pagebreak\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scEw2gkFYy83"
      },
      "source": [
        "\n",
        "# Submission instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWcupmrvYy9C"
      },
      "source": [
        "Follow the instructions precisely\n",
        "1. Run the whole notebook up to this point\n",
        "  * Click on this text cell and go to Runtime > Run before\n",
        "  * It is essential that the notebook can be run from start to finish without us having to change anything.\n",
        "2. Download the current notebook\n",
        "  * File -> Download -> Download .ipynb\n",
        "3. Upload the downloaded notebook in the current runtime\n",
        "  * In the left sidebar menu, open the last tab (Files)\n",
        "  * Click on the first button under the File title (Page with arrow pointing up)\n",
        "  * In the new window, upload the notebook just downloaded\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfw5_7NlYy9D"
      },
      "source": [
        "4. To turn the notebook into a pdf you need to install a Tex extension: run the next cell of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTdv9NEuYy9E",
        "outputId": "fbcbd88b-cf3b-4a71-d657-18fea9263856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/bin/sh: apt-get: command not found\n"
          ]
        }
      ],
      "source": [
        "#REMOVE_CELL#\n",
        "!apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgmWSW-MYy9F"
      },
      "source": [
        "5. Now, run the next cell to set some cell tags in the notebook file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMNhHjhbYy9F"
      },
      "outputs": [],
      "source": [
        "#REMOVE_CELL#\n",
        "import nbformat as nbf\n",
        "from glob import glob\n",
        "notebooks = glob(\"/content/**/*.ipynb\", recursive=True)\n",
        "\n",
        "text_search_dict = [\"YOUR TEXT STARTS HERE\",\"#YOUR CODE STARTS HERE#\"]\n",
        "\n",
        "for ipath in notebooks:\n",
        "    print(ipath)\n",
        "    ntbk = nbf.read(ipath, nbf.NO_CONVERT)\n",
        "\n",
        "    for cell in ntbk.cells:\n",
        "        cell_type = cell['cell_type'] == \"code\"\n",
        "\n",
        "        cell_tags = cell.get('metadata', {}).get('tags', [])\n",
        "        cell_tags = set(cell_tags)\n",
        "\n",
        "        if cell_type == 0: #markdown\n",
        "          if (cell['source'][0]!=\"#\" and text_search_dict[cell_type] not in cell['source'] and \"pagebreak\" not in cell['source']) or \"#REMOVE_CELL#\" in cell['source']:\n",
        "            cell_tags.add(\"remove_cell\")\n",
        "\n",
        "        else: #code\n",
        "          #if text_search_dict[cell_type] not in cell['source'] or \"#REMOVE_CELL#\" in cell['source']:\n",
        "          if \"#REMOVE_CELL#\" in cell['source']:\n",
        "            cell_tags.add(\"remove_cell\")\n",
        "          elif \"#REMOVE_OUTPUT#\" in cell['source']:\n",
        "            cell_tags.add(\"remove_output\")\n",
        "\n",
        "        if len(cell_tags) > 0:\n",
        "            cell['metadata']['tags'] = list(cell_tags)\n",
        "\n",
        "    nbf.write(ntbk, ipath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttb36qjjYy9F"
      },
      "source": [
        "6. Now, run the next cell to transform the notebook to PDF without the code cells.\n",
        "  * The file will appear in the menu on the left (refresh if needed). The file should be named `DMT2023_HW4.pdf`\n",
        "  * Rename this file **Surname1_Surname2_DMT2023_HW4_report.pdf** (e.g. Becchetti_Siciliano_DMT2023_HW4_report.pdf). Sort the surnames alphabetically.\n",
        "  * Click on it and using the right button or the three dots at its side, click on download to transfer it to your local PC\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3cgJxIBYy9H",
        "outputId": "b99e74bb-4a45-40f6-da61-965f33404995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[NbConvertApp] WARNING | pattern '/content/DMT2023_HW4.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#REMOVE_CELL#\n",
        "!jupyter nbconvert /content/DMT2023_HW4.ipynb --to pdf --TagRemovePreprocessor.remove_cell_tags='{\"remove_cell\"}' -TagRemovePreprocessor.remove_all_outputs_tags='{\"remove_output\"}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2_OqvVwYy9H"
      },
      "source": [
        "7. Now, rename the downloaded notebook **Surname1_Surname2_DMT2023_HW4_notebook.ipynb** (e.g. Becchetti_Siciliano_DMT2023_HW4_notebook.ipynb). Sort the surnames alphabetically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCjj-I1_Yy9H"
      },
      "source": [
        "8. Now that you have both files, you need to upload them to Classroom. Only the student with the surname that comes first in alphabetical order **must** upload the files. Only the files uploaded by this student will be graded."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "008e9f1470004dd5bd627f0c4769d1f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f25620a669f46b090c85b17a4507d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f86700fe7494a41bccc5ac730ddd11f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8c7b23c4294347901b6affeccdb3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52dacec48c6a4bdaa051a67e4266857b",
              "IPY_MODEL_919c93a973c54bd3888de039f7a33ee4",
              "IPY_MODEL_391224847a04491d953d97dffd194f28"
            ],
            "layout": "IPY_MODEL_5af83cdb5a3e4886953d857bffb5fe16"
          }
        },
        "391224847a04491d953d97dffd194f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a89aefea9b4a8fa49be4402e5c9711",
            "placeholder": "​",
            "style": "IPY_MODEL_5b70b56e487a43ef8a7eea5c65daa10c",
            "value": " 580/580 [01:55&lt;00:00, 17.76it/s]"
          }
        },
        "3b4011bdc37d44a58d5ab1207cb981a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454f4e6c66944ee08cbda6c7316b6c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52dacec48c6a4bdaa051a67e4266857b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008e9f1470004dd5bd627f0c4769d1f1",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b9273face34883b54475d9b0881716",
            "value": "Batches: 100%"
          }
        },
        "55a89aefea9b4a8fa49be4402e5c9711": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af83cdb5a3e4886953d857bffb5fe16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b70b56e487a43ef8a7eea5c65daa10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e074e469b3c4de0ade713f93bd88979": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814a414dc4414fc99a6a2f40d5730e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f25620a669f46b090c85b17a4507d67",
            "max": 580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90f9ae0d934049d3a6170e2209dc7dda",
            "value": 580
          }
        },
        "81b4ecb83ac642b4bf445eb44d191e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ca274683d004d56870d423d3932cb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f86700fe7494a41bccc5ac730ddd11f",
            "placeholder": "​",
            "style": "IPY_MODEL_454f4e6c66944ee08cbda6c7316b6c02",
            "value": "Batches: 100%"
          }
        },
        "90f9ae0d934049d3a6170e2209dc7dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "919c93a973c54bd3888de039f7a33ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f62ecf96ed4b40418652c7b4251e40a2",
            "max": 580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7d2feedff0c482999384d54ef21de54",
            "value": 580
          }
        },
        "a0d5159e7fcb4767aff1dcbb57582eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4011bdc37d44a58d5ab1207cb981a8",
            "placeholder": "​",
            "style": "IPY_MODEL_81b4ecb83ac642b4bf445eb44d191e05",
            "value": " 580/580 [00:42&lt;00:00, 35.98it/s]"
          }
        },
        "c6b9273face34883b54475d9b0881716": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfd9513f680e4b749b13188316e6d4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ca274683d004d56870d423d3932cb88",
              "IPY_MODEL_814a414dc4414fc99a6a2f40d5730e25",
              "IPY_MODEL_a0d5159e7fcb4767aff1dcbb57582eb6"
            ],
            "layout": "IPY_MODEL_6e074e469b3c4de0ade713f93bd88979"
          }
        },
        "f62ecf96ed4b40418652c7b4251e40a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d2feedff0c482999384d54ef21de54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}